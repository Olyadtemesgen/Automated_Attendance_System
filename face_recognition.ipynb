{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 274 images belonging to 19 classes.\n",
      "Found 66 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning CNN model to recognize face\n",
    "'''This script uses a database of images and creates CNN model on top of it to test\n",
    "   if the given image is recognized correctly or not'''\n",
    "\n",
    "'''####### IMAGE PRE-PROCESSING for TRAINING and TESTING data #######'''\n",
    "\n",
    "# Specifying the folder where images are present\n",
    "TrainingImagePath='/home/olitye/Code/AI/CNN/Face-Images/Final Training Images'\n",
    "TestImagePath = '/home/olitye/Code/AI/CNN/Face-Images/Final Testing Images'\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Understand more about ImageDataGenerator at below link\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "# Defining pre-processing transformations on raw images of training data\n",
    "# These hyper parameters helps to generate slightly twisted versions\n",
    "# of the original image, which leads to a better model, since it learns\n",
    "# on the good and bad mix of images\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Defining pre-processing transformations on raw images of testing data\n",
    "# No transformations are done on the testing images\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Generating the Training Data\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "# Generating the Testing Data\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        TestImagePath,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Printing class labels for each face\n",
    "test_set.class_indices\n",
    "# training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of Face and its ID {0: 'DDD', 1: 'Olyad-A-Male-1234', 2: 'ddd', 3: 'face1', 4: 'face10', 5: 'face11', 6: 'face12', 7: 'face13', 8: 'face14', 9: 'face15', 10: 'face16', 11: 'face2', 12: 'face3', 13: 'face4', 14: 'face5', 15: 'face6', 16: 'face7', 17: 'face8', 18: 'face9'}\n",
      "\n",
      " The Number of output neurons:  19\n"
     ]
    }
   ],
   "source": [
    "'''############ Creating lookup table for all faces ############'''\n",
    "# class_indices have the numeric tag for each face\n",
    "TrainClasses=training_set.class_indices\n",
    "\n",
    "# Storing the face and the numeric tag for future reference\n",
    "ResultMap={}\n",
    "for faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n",
    "    ResultMap[faceValue]=faceName\n",
    "\n",
    "# Saving the face map for future reference\n",
    "import pickle\n",
    "with open(\"ResultsMap.pkl\", 'wb') as fileWriteStream:\n",
    "    pickle.dump(ResultMap, fileWriteStream)\n",
    "\n",
    "# The model will give answer as a numeric tag\n",
    "# This mapping will help to get the corresponding face name for it\n",
    "print(\"Mapping of Face and its ID\",ResultMap)\n",
    "\n",
    "# The number of neurons for the output layer is equal to the number of faces\n",
    "OutputNeurons=len(ResultMap)\n",
    "print('\\n The Number of output neurons: ', OutputNeurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 18:48:23.670443: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-17 18:48:23.862731: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-17 18:48:23.862793: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-17 18:48:23.866061: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-17 18:48:23.881647: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-17 18:48:23.883041: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 18:48:25.835576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 274 images belonging to 19 classes.\n",
      "Found 94 images belonging to 19 classes.\n",
      "Mapping of Face and its ID {0: 'DDD', 1: 'Olyad-A-Male-1234', 2: 'ddd', 3: 'face1', 4: 'face10', 5: 'face11', 6: 'face12', 7: 'face13', 8: 'face14', 9: 'face15', 10: 'face16', 11: 'face2', 12: 'face3', 13: 'face4', 14: 'face5', 15: 'face6', 16: 'face7', 17: 'face8', 18: 'face9'}\n",
      "\n",
      " The Number of output neurons:  19\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 102.6871 - accuracy: 0.0469WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "8/8 [==============================] - 5s 384ms/step - loss: 102.6871 - accuracy: 0.0469 - val_loss: 3.3675 - val_accuracy: 0.1383\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 251ms/step - loss: 3.0402 - accuracy: 0.0992\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 254ms/step - loss: 2.7255 - accuracy: 0.1758\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 248ms/step - loss: 2.2576 - accuracy: 0.3398\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 1.6661 - accuracy: 0.5372\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 232ms/step - loss: 1.1410 - accuracy: 0.7355\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 236ms/step - loss: 0.7699 - accuracy: 0.8125\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.4401 - accuracy: 0.8926\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 233ms/step - loss: 0.3846 - accuracy: 0.8711\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 239ms/step - loss: 0.5459 - accuracy: 0.8554\n",
      "###### Total Time Taken:  0 Minutes ######\n",
      "Found 274 images belonging to 19 classes.\n",
      "Found 94 images belonging to 19 classes.\n",
      "Mapping of Face and its ID {0: 'DDD', 1: 'Olyad-A-Male-1234', 2: 'ddd', 3: 'face1', 4: 'face10', 5: 'face11', 6: 'face12', 7: 'face13', 8: 'face14', 9: 'face15', 10: 'face16', 11: 'face2', 12: 'face3', 13: 'face4', 14: 'face5', 15: 'face6', 16: 'face7', 17: 'face8', 18: 'face9'}\n",
      "\n",
      " The Number of output neurons:  19\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 51.8770 - accuracy: 0.0661WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "8/8 [==============================] - 4s 356ms/step - loss: 51.8770 - accuracy: 0.0661 - val_loss: 3.4713 - val_accuracy: 0.0851\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 2.8782 - accuracy: 0.1322\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 234ms/step - loss: 2.3211 - accuracy: 0.3099\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 1.2682 - accuracy: 0.6281\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.7402 - accuracy: 0.7934\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.5332 - accuracy: 0.8595\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 230ms/step - loss: 0.2973 - accuracy: 0.9256\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.2142 - accuracy: 0.9339\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.2223 - accuracy: 0.9463\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.2211 - accuracy: 0.9339\n",
      "###### Total Time Taken:  0 Minutes ######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olitye/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "\n",
    "# Calling the training function\n",
    "# This function will return the trained model\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-17 16:22:34.707628: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-17 16:22:34.805194: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-17 16:22:34.805257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-17 16:22:34.807933: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-17 16:22:34.823126: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-17 16:22:34.824362: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-17 16:22:36.927673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m test_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(test_image)\n\u001b[1;32m     14\u001b[0m test_image\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mexpand_dims(test_image,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mclassifier\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(test_image,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#print(training_set.class_indices)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(\"result\", result)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print the maximum number in result\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(result[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "'''########### Making single predictions ###########'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "olyad_image = '/home/olitye/Code/AI/CNN/TestImages/face_11.jpg'\n",
    "\n",
    "test_image = image.load_img(olyad_image, target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "result=classifier.predict(test_image,verbose=0)\n",
    "#print(training_set.class_indices)\n",
    "\n",
    "# print(\"result\", result)\n",
    "# print the maximum number in result\n",
    "print(max(result[0]))\n",
    "# print(result)\n",
    "print('####'*10)\n",
    "print('Prediction is: ',ResultMap[np.argmax(result)])\n",
    "# for idx in range(16):\n",
    "\n",
    "#     another_image = '/home/olitye/Code/AI/CNN/Face-Images/Face Images/Final Testing Images/face{}/3face{}.jpg'.format(idx + 1, idx + 1)\n",
    "\n",
    "#     test_image = image.load_img(another_image, target_size=(64, 64))\n",
    "#     test_image = image.img_to_array(test_image)\n",
    "\n",
    "#     test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "#     result=classifier.predict(test_image,verbose=0)\n",
    "#     #print(training_set.class_indices)\n",
    "\n",
    "#     # print(\"result\", result)\n",
    "#     # print the maximum number in result\n",
    "#     print(max(result[0]))\n",
    "#     # print(result)\n",
    "#     print('####'*10)\n",
    "#     print('Prediction is: ',ResultMap[np.argmax(result)])\n",
    "\n",
    "ImagePath='/home/olitye/Code/AI/CNN/Face-Images/Face Images/Final Testing Images/data.jpg'\n",
    "test_image=image.load_img(ImagePath,target_size=(64, 64))\n",
    "test_image=image.img_to_array(test_image)\n",
    "\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "result=classifier.predict(test_image,verbose=0)\n",
    "print(training_set.class_indices)\n",
    "print(\"result\", result)\n",
    "print('####'*10)\n",
    "print('Prediction is: ',ResultMap[np.argmax(result)])\n",
    "\n",
    "import face_recognition\n",
    "\n",
    "image_path = \"/home/olitye/Code/AI/CNN/students.jpg\"\n",
    "images = face_recognition.load_image_file(image_path)\n",
    "\n",
    "import os\n",
    "face_locations = face_recognition.face_locations(images)\n",
    "# recognize_faces(face_locations, images)\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "images_name = []\n",
    "for idx, face_location in enumerate(face_locations):\n",
    "    top, right, bottom, left = face_location\n",
    "\n",
    "    top = max(0, top )\n",
    "    left = max(0, left )\n",
    "    right = right \n",
    "    bottom = bottom \n",
    "\n",
    "    # print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "    face_image = images[top:bottom, left:right]\n",
    "\n",
    "    \n",
    "    # save image in a folder TestImages\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "\n",
    "    # create a folder TestImages if not exists\n",
    "    if not os.path.exists('/home/olitye/Code/AI/CNN/TestImages'):\n",
    "        os.makedirs('/home/olitye/Code/AI/CNN/TestImages')\n",
    "    \n",
    "\n",
    "    pil_image.save(\"/home/olitye/Code/AI/CNN/TestImages/face_{}.jpg\".format(idx))\n",
    "\n",
    "    #save the image absolute path into images_name\n",
    "    images_name.append('/home/olitye/Code/AI/CNN/TestImages/face_{}.jpg'.format(idx))\n",
    "\n",
    "for image_path in images_name:\n",
    "    test_image=image.load_img(image_path,target_size=(64, 64))\n",
    "    \n",
    "    test_image=image.img_to_array(test_image)\n",
    "\n",
    "    test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "    result=classifier.predict(test_image,verbose=0)\n",
    "    #print(training_set.class_indices)\n",
    "\n",
    "    # print(\"result\", result)\n",
    "\n",
    "    # return the maximum index\n",
    "    print(max(result[0]))\n",
    "    print('####'*10)\n",
    "    print('Prediction is: ',ResultMap[np.argmax(result)])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student already exists in the Excel file.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n",
      "I found 1 face(s) in this photograph.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import openpyxl\n",
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "def add_student(zipFileName: str):\n",
    "    # student name is the zipped file name without the extension\n",
    "    #student name has the form name-section-gender-id so we split it\n",
    "    student_name = os.path.splitext(zipFileName)[0]\n",
    "    name, section, gender, id = os.path.splitext(zipFileName)[0].split('-')\n",
    "\n",
    "    # Add the student to the Excel file\n",
    "    add_student_to_excel(\"/home/olitye/Code/AI/CNN/attendance/SAMPLE.xlsx\", name, id, section, gender)\n",
    "\n",
    "    # Extract the zipped file\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(zipFileName, 'r') as zip_ref:\n",
    "        # Extract the contents to a temporary directory\n",
    "        zip_ref.extractall(student_name)\n",
    "\n",
    "    # Get the path to the extracted folder (student_name/student_name)\n",
    "    extracted_folder = os.path.join(student_name, student_name)\n",
    "\n",
    "    # Get the destination directory to save the unzipped file\n",
    "    destination_directory = '/home/olitye/Code/AI/CNN/Face-Images/Final Training Images'\n",
    "\n",
    "    # Move the contents of the extracted folder to the destination director\n",
    "    shutil.move(extracted_folder, destination_directory)\n",
    "    # Remove the temporary parent folder (student_name)\n",
    "    os.rmdir(student_name)\n",
    "\n",
    "    # Go Through the images and detect only one faces and save it to that the same image file\n",
    "    # Get the path to the extracted folder (student_name/student_name)\n",
    "\n",
    "    for image_path in os.listdir(destination_directory + '/' + student_name):\n",
    "        images = face_recognition.load_image_file(destination_directory + '/' + student_name + '/' + image_path)\n",
    "\n",
    "        face_locations = face_recognition.face_locations(images)\n",
    "        # recognize_faces(face_locations, images)\n",
    "        print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "        images_name = []\n",
    "        for idx, face_location in enumerate(face_locations):\n",
    "            top, right, bottom, left = face_location\n",
    "\n",
    "            top = max(0, top )\n",
    "            left = max(0, left )\n",
    "            right = right \n",
    "            bottom = bottom \n",
    "\n",
    "            # print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "            face_image = images[top:bottom, left:right]\n",
    "\n",
    "            \n",
    "            # save image in a folder TestImages\n",
    "            pil_image = Image.fromarray(face_image)\n",
    "\n",
    "            # image the image to the same path\n",
    "            pil_image.save(destination_directory + '/' + student_name + '/' + image_path)\n",
    "\n",
    "            break\n",
    "           \n",
    "\n",
    "\n",
    "def is_student_unique(sheet, student_name, student_id, section, gender):\n",
    "    # Iterate over rows in the sheet\n",
    "    for row in sheet.iter_rows(min_row=2):\n",
    "        existing_name = row[0].value\n",
    "        existing_id = row[1].value\n",
    "        existing_section = row[2].value\n",
    "        existing_gender = row[3].value\n",
    "\n",
    "        # Check if the student already exists in the sheet\n",
    "        if (\n",
    "            existing_name == student_name\n",
    "            and existing_id == student_id\n",
    "            and existing_section == section\n",
    "            and existing_gender == gender\n",
    "        ):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def add_student_to_excel(excel_file_path, student_name, student_id, section, gender):\n",
    "    # Load the Excel file\n",
    "    wb = openpyxl.load_workbook(excel_file_path)\n",
    "\n",
    "    # Select the active sheet (you may need to modify this based on your Excel file structure)\n",
    "    sheet = wb.active\n",
    "\n",
    "    # Check if the student is already in the Excel file\n",
    "    if not is_student_unique(sheet, student_name, student_id, section, gender):\n",
    "        print(\"Student already exists in the Excel file.\")\n",
    "        wb.close()\n",
    "        return\n",
    "\n",
    "    # Find the column index of the first empty row\n",
    "    row_index = sheet.max_row + 1\n",
    "\n",
    "    # Write the student information in separate columns\n",
    "    sheet.cell(row=row_index, column=1).value = student_name\n",
    "    sheet.cell(row=row_index, column=2).value = student_id\n",
    "    sheet.cell(row=row_index, column=3).value = section\n",
    "    sheet.cell(row=row_index, column=4).value = gender\n",
    "\n",
    "    # Save the modified Excel file\n",
    "    wb.save(excel_file_path)\n",
    "    wb.close()\n",
    "\n",
    "add_student('Olyad-A-Male-1234.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
